#!/usr/bin/env python3
"""
Gemini 2.5 Flash Preview æ¨¡å‹æµ‹è¯•è„šæœ¬
ç”¨äºæ’æŸ¥ gemini-2.5-flash-preview-04-17 æ¥å£æµ‹è¯•æ— å›å¤é—®é¢˜
"""

import os
import sys
import time
import requests
from openai import OpenAI

# æ·»åŠ Djangoé¡¹ç›®è·¯å¾„
sys.path.append('/Users/wangfuyu/PythonCode/FT-Django')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'stock_analysis.settings')

import django
django.setup()

from apps.api_management.models import ApiProvider, ApiToken, ApiInterface

def test_gemini_direct():
    """ç›´æ¥æµ‹è¯•Geminiæ¨¡å‹"""
    print("=== ç›´æ¥æµ‹è¯• Gemini 2.5 Flash Preview ===\n")
    
    try:
        # è·å–æ¨ç†æ—¶ä»£çš„APIé…ç½®
        provider = ApiProvider.objects.filter(name__icontains='aihubmix').first()
        if not provider:
            print("âŒ æœªæ‰¾åˆ°æ¨ç†æ—¶ä»£APIæä¾›å•†é…ç½®")
            return False
            
        print(f"âœ… æ‰¾åˆ°APIæä¾›å•†: {provider.display_name}")
        print(f"   Base URL: {provider.base_url}")
        
        # è·å–API Token
        token = ApiToken.objects.filter(provider=provider, is_active=True).first()
        if not token:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„API Token")
            return False
            
        print(f"âœ… æ‰¾åˆ°æœ‰æ•ˆToken: {token.token[:10]}...")
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
        client = OpenAI(
            base_url=provider.base_url,
            api_key=token.token,
            timeout=600.0  # 10åˆ†é’Ÿè¶…æ—¶
        )
        
        print("\nğŸ”„ å¼€å§‹æµ‹è¯• gemini-2.5-flash-preview-04-17...")
        start_time = time.time()
        
        # æµ‹è¯•è¯·æ±‚
        completion = client.chat.completions.create(
            model="gemini-2.5-flash-preview-04-17",
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ],
            temperature=0.7,
            max_tokens=1024
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        print(f"\nâœ… æµ‹è¯•æˆåŠŸï¼å“åº”æ—¶é—´: {response_time:.2f}ç§’")
        print(f"æ¨¡å‹å›å¤: {completion.choices[0].message.content}")
        print(f"Tokenä½¿ç”¨æƒ…å†µ:")
        print(f"  - è¾“å…¥Token: {completion.usage.prompt_tokens}")
        print(f"  - è¾“å‡ºToken: {completion.usage.completion_tokens}")
        print(f"  - æ€»Token: {completion.usage.total_tokens}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        return False

def test_gemini_via_requests():
    """ä½¿ç”¨requestsåº“ç›´æ¥æµ‹è¯•API"""
    print("\n=== ä½¿ç”¨ requests ç›´æ¥æµ‹è¯• API ===\n")
    
    try:
        # è·å–é…ç½®
        provider = ApiProvider.objects.filter(name__icontains='aihubmix').first()
        token = ApiToken.objects.filter(provider=provider, is_active=True).first()
        
        if not provider or not token:
            print("âŒ ç¼ºå°‘å¿…è¦çš„é…ç½®ä¿¡æ¯")
            return False
        
        url = f"{provider.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {token.token}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "gemini-2.5-flash-preview-04-17",
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ],
            "temperature": 0.7,
            "max_tokens": 1024
        }
        
        print(f"ğŸ”„ å‘é€è¯·æ±‚åˆ°: {url}")
        start_time = time.time()
        
        response = requests.post(
            url, 
            json=data, 
            headers=headers, 
            timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        print(f"\nğŸ“Š å“åº”çŠ¶æ€ç : {response.status_code}")
        print(f"ğŸ“Š å“åº”æ—¶é—´: {response_time:.2f}ç§’")
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… è¯·æ±‚æˆåŠŸï¼")
            print(f"æ¨¡å‹å›å¤: {result['choices'][0]['message']['content']}")
            if 'usage' in result:
                print(f"Tokenä½¿ç”¨æƒ…å†µ:")
                print(f"  - è¾“å…¥Token: {result['usage']['prompt_tokens']}")
                print(f"  - è¾“å‡ºToken: {result['usage']['completion_tokens']}")
                print(f"  - æ€»Token: {result['usage']['total_tokens']}")
            return True
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥")
            print(f"å“åº”å†…å®¹: {response.text}")
            return False
            
    except requests.exceptions.Timeout:
        print("âŒ è¯·æ±‚è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")
        return False

def test_other_gemini_models():
    """æµ‹è¯•å…¶ä»–Geminiæ¨¡å‹ä½œä¸ºå¯¹æ¯”"""
    print("\n=== æµ‹è¯•å…¶ä»– Gemini æ¨¡å‹ä½œä¸ºå¯¹æ¯” ===\n")
    
    models_to_test = [
        "gemini-pro",
        "gemini-1.5-pro",
        "gemini-1.5-flash"
    ]
    
    try:
        provider = ApiProvider.objects.filter(name__icontains='aihubmix').first()
        token = ApiToken.objects.filter(provider=provider, is_active=True).first()
        
        if not provider or not token:
            print("âŒ ç¼ºå°‘å¿…è¦çš„é…ç½®ä¿¡æ¯")
            return
        
        client = OpenAI(
            base_url=provider.base_url,
            api_key=token.token,
            timeout=60.0  # 1åˆ†é’Ÿè¶…æ—¶
        )
        
        for model in models_to_test:
            print(f"ğŸ”„ æµ‹è¯•æ¨¡å‹: {model}")
            try:
                start_time = time.time()
                completion = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "user", "content": "ä½ å¥½"}
                    ],
                    temperature=0.7,
                    max_tokens=100
                )
                end_time = time.time()
                print(f"  âœ… {model} æµ‹è¯•æˆåŠŸï¼Œå“åº”æ—¶é—´: {end_time - start_time:.2f}ç§’")
            except Exception as e:
                print(f"  âŒ {model} æµ‹è¯•å¤±è´¥: {str(e)}")
            print()
            
    except Exception as e:
        print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ Gemini 2.5 Flash Preview é—®é¢˜æ’æŸ¥\n")
    print("=" * 60)
    
    # æµ‹è¯•1: ä½¿ç”¨OpenAIå®¢æˆ·ç«¯
    success1 = test_gemini_direct()
    
    # æµ‹è¯•2: ä½¿ç”¨requestsç›´æ¥è°ƒç”¨
    success2 = test_gemini_via_requests()
    
    # æµ‹è¯•3: å¯¹æ¯”å…¶ä»–æ¨¡å‹
    test_other_gemini_models()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print(f"  - OpenAIå®¢æˆ·ç«¯æµ‹è¯•: {'âœ… æˆåŠŸ' if success1 else 'âŒ å¤±è´¥'}")
    print(f"  - requestsç›´æ¥æµ‹è¯•: {'âœ… æˆåŠŸ' if success2 else 'âŒ å¤±è´¥'}")
    
    if success1 or success2:
        print("\nğŸ‰ ç»“è®º: gemini-2.5-flash-preview-04-17 æ¨¡å‹å¯ä»¥æ­£å¸¸å·¥ä½œ")
        print("   é—®é¢˜å¯èƒ½å‡ºç°åœ¨åº”ç”¨çš„å…¶ä»–éƒ¨åˆ†ï¼Œå»ºè®®æ£€æŸ¥:")
        print("   1. å‰ç«¯è¯·æ±‚å¤„ç†é€»è¾‘")
        print("   2. åç«¯APIæ¥å£å®ç°")
        print("   3. æ•°æ®åº“æ¥å£é…ç½®")
    else:
        print("\nâš ï¸  ç»“è®º: gemini-2.5-flash-preview-04-17 æ¨¡å‹æ— æ³•æ­£å¸¸å·¥ä½œ")
        print("   è¿™å¯èƒ½æ˜¯æ¨¡å‹æä¾›å•†çš„é—®é¢˜ï¼Œå»ºè®®:")
        print("   1. è”ç³»æ¨ç†æ—¶ä»£å®¢æœ")
        print("   2. æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
        print("   3. ç¡®è®¤è´¦æˆ·æƒé™å’Œä½™é¢")

if __name__ == "__main__":
    main()